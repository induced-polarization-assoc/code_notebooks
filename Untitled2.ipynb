{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the Functionality with Real Data!\n",
    "04.08.2020\n",
    "by jjr\n",
    "\n",
    "---\n",
    "Now, a real sample dataset from oil-under-ice will be loaded and a single packet will be processed with this DSP algorithm to ensure compatibility and proper operation.    \n",
    "\n",
    "First, the functions are defined for the DSP algorithms applied. \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.  The DSP Algorithm Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  module imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Global Constants for an Analysis\n",
    "PACKET_NUMBER = 1\n",
    "SAMPLE_PERIOD = 1  # seconds\n",
    "PI = np.pi  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_data(input_file_string):\n",
    "    input_file_path = os.path.join(os.getcwd(), input_file)\n",
    "    print(input_file_path)\n",
    "    p_start_marker = f\"${PACKET_NUMBER}\\n\"  # consider using a regex here instead for better precision/accuracy\n",
    "    p_end_marker = \"*\"\n",
    "\n",
    "    # This parsing method seems quite speedy with a bunch of lazy evaluation... \n",
    "    # interestingly, the next() method for generators will allow for iteration through \n",
    "    # ALL packets lazily. \n",
    "    with open(input_file_path, \"r\") as file:\n",
    "        lines = file.readlines()\n",
    "        start_generator = (index for index, line in enumerate(lines) if line.startswith(p_start_marker))\n",
    "        end_generator = (index for index, line in enumerate(lines) if line.startswith(p_end_marker))\n",
    "        raw_packet_list = lines[next(start_generator) + 10: next(end_generator)]\n",
    "        \n",
    "    raw_signals_matrix = np.genfromtxt(raw_packet_list, delimiter=\",\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_derived_constants(signals_matrix, PERIOD):\n",
    "    # Everything seems in order here, which is good... \n",
    "    # One can also derive the array dimensions needed in the next steps from the input \n",
    "    # file alone with no other a priori knowledge with is also good. \n",
    "    N_SAMPLES = signals_matrix.shape[0]\n",
    "    Q_CHANNELS = signals_matrix.shape[-1]\n",
    "    F_S = np.divide(N_SAMPLES, PERIOD)\n",
    "    TAU = np.divide(1, F_S)\n",
    "    \n",
    "    # verbose testprint for debugging:\n",
    "    print(f\"Array loaded for packet {PACKET_NUMBER}: Dimensions ({N_SAMPLES} X {Q_CHANNELS})\")\n",
    "    print(f\"Sampling Frequency: {F_S} [S/s] , sampled over {PERIOD} seconds)\")\n",
    "    \n",
    "    return N_SAMPLES, Q_CHANNELS, F_S, TAU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
